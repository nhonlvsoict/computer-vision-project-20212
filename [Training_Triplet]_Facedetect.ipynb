{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Training_Triplet]_Facedetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhonlvsoict/computer-vision-project-20212/blob/master/%5BTraining_Triplet%5D_Facedetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiR7oJn4h4WE",
        "outputId": "9095f2b7-1646-406f-be9c-f6ac745670c1"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--3iW5htq8TC",
        "outputId": "2032bbbb-13d3-4c6a-bf08-fea7b66dc83f"
      },
      "source": [
        "!pip uninstall -y keras-nightly\n",
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.1.5\n",
        "!pip install h5py==2.10.0\n",
        "!pip install tensorflow_gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 27kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 38.6MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.5.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=3ab6169774ba913edc8a1a42c2291541098b33d76c93f8a4faf1086cf1e562f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.5\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Collecting tensorflow_gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow_gpu==1.15.0) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.0) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.0) (3.4.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjYxgZ8pioMe"
      },
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruYJq980nUVn"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/X_train_tripletCNN.pkl', 'rb') as f:\n",
        "    X = pickle.load(f)\n",
        "    X = np.array(X)\n",
        "    X=X[2400:]\n",
        "    X = X/255.\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/y_train_tripletCNN.pkl', 'rb') as f:\n",
        "    y = pickle.load(f)\n",
        "    y = np.array(y)\n",
        "    y=y[2400:]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/name_mapCNN.pkl', 'rb') as f:\n",
        "    name_map = pickle.load(f)\n",
        "    # name_map=name_map[2400:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ7hU-sJ0XcO"
      },
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC0BtbaF9OvU"
      },
      "source": [
        "np.shape(X), np.shape(y), np.shape(name_map)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPYMxN2tvgF5"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import applications"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d84U9ihiHbFi"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import h5py\n",
        "import tensorflow.keras.applications.vgg16 as vgg16\n",
        "\n",
        "def triplet_model():\n",
        "    #first branch\n",
        "    vgg_model = vgg16.VGG16(weights=None, include_top=False, input_shape=(221, 221, 3))\n",
        "    first_vgg = vgg_model.output\n",
        "    first_vgg = GlobalAveragePooling2D()(first_vgg)\n",
        "    first_vgg = Dense(4096, activation='relu')(first_vgg)\n",
        "    first_vgg = Dropout(0.6)(first_vgg)\n",
        "    first_vgg = Dense(4096, activation='relu')(first_vgg)\n",
        "    first_vgg = Dropout(0.6)(first_vgg)\n",
        "    first_vgg = Lambda(lambda x: K.l2_normalize(x,axis=1))(first_vgg)\n",
        "    first_branch = Model(inputs=vgg_model.input, outputs=first_vgg)\n",
        "\n",
        "    #second branch\n",
        "    second_branch = Input(shape=(221, 221, 3))\n",
        "    second_conv = Conv2D(96, kernel_size=(8,8), strides=(16,16), padding='same')(second_branch)\n",
        "    second_max = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')(second_conv)\n",
        "    second_max = Flatten()(second_max)\n",
        "    second_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(second_max)\n",
        "\n",
        "    #third branch\n",
        "    third_branch = Input(shape=(221, 221, 3))\n",
        "    third_conv = Conv2D(96, kernel_size=(8,8), strides=(32,32), padding='same')(third_branch)\n",
        "    third_max = MaxPool2D(pool_size=(7,7), strides=(4,4), padding='same')(third_conv)\n",
        "    third_max = Flatten()(third_max)\n",
        "    third_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(third_max)\n",
        "                       \n",
        "    merge_one = concatenate([second_max, third_max])\n",
        "    merge_two = concatenate([merge_one, first_branch.output])\n",
        "    emb = Dense(4096)(merge_two)\n",
        "    emb = Dense(128)(emb)\n",
        "    l2_norm_final = Lambda(lambda x: K.l2_normalize(x, axis=1))(emb)\n",
        "                        \n",
        "    final_model = Model(inputs=[second_branch, third_branch, first_branch.input], outputs=l2_norm_final)\n",
        "\n",
        "    return final_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVwwf38VHmWq",
        "outputId": "f60c76b7-01e3-422b-bc6b-e1b98e755649"
      },
      "source": [
        "triplet_model = triplet_model()\n",
        "triplet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 221, 221, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 221, 221, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 221, 221, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 110, 110, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 110, 110, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 110, 110, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 55, 55, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 55, 55, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 55, 55, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 27, 27, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 27, 27, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 27, 27, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 27, 27, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 13, 13, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 13, 13, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 13, 13, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 13, 13, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 221, 221, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 221, 221, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 14, 14, 96)   18528       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 7, 7, 96)     18528       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4096)         2101248     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 7, 7, 96)     0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 96)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4096)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4704)         0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4096)         16781312    dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4704)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 384)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5088)         0           lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 4096)         0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 9184)         0           concatenate[0][0]                \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4096)         37621760    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          524416      dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 128)          0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 71,780,480\n",
            "Trainable params: 71,780,480\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHY7XziPKu94"
      },
      "source": [
        "batch_size = 24\n",
        "\n",
        "_EPSILON = K.epsilon()\n",
        "def triplet_loss(y_true, y_pred):\n",
        "    y_pred = K.clip(y_pred, _EPSILON, 1.0 - _EPSILON)\n",
        "    loss = 0.\n",
        "    g = 1.\n",
        "    for i in range(0, batch_size, 3):\n",
        "        try:\n",
        "            q_embedding = y_pred[i]\n",
        "            p_embedding = y_pred[i+1]\n",
        "            n_embedding = y_pred[i+2]\n",
        "            D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2))\n",
        "            D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2))\n",
        "            loss = loss + g + D_q_p - D_q_n\n",
        "        except:\n",
        "            continue\n",
        "    loss = loss/batch_size*3\n",
        "    return K.maximum(loss, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lcWgrgK2HH"
      },
      "source": [
        "triplet_model.compile(loss=triplet_loss, optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4AZD-UMIbjA"
      },
      "source": [
        "def image_batch_generator(images, labels, batch_size):\n",
        "    labels = np.array(labels)\n",
        "    while True:\n",
        "        batch_paths = np.random.choice(a = len(images), size = batch_size//3)\n",
        "        input_1 = []\n",
        "        \n",
        "        for i in batch_paths:\n",
        "            p = np.where(labels == labels[i])[0]\n",
        "            n = np.where(labels != labels[i])[0]\n",
        "            \n",
        "            j = np.random.choice(p)\n",
        "            while j == i:\n",
        "                j = np.random.choice(p)\n",
        "             \n",
        "            k = np.random.choice(n)\n",
        "            while k == i:\n",
        "                k = np.random.choice(n)\n",
        "            \n",
        "            input_1.append(images[i])\n",
        "            input_1.append(images[j])\n",
        "            input_1.append(images[k])\n",
        "\n",
        "        input_1 = np.array(input_1)\n",
        "        input = [input_1, input_1, input_1]\n",
        "        yield(input, np.zeros((batch_size, )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNpgPSzSz_4g"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = '/content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEQ3O2pqMFf9",
        "outputId": "52d6ee5e-6c9e-4870-ea27-4ce467ab5ce7"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "print(\"Loading pre-trained weight\")\n",
        "triplet_model.load_weights('/content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pre-trained weight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QTwIM190EKg",
        "outputId": "6827e623-aca7-4719-dc22-c11e97290267"
      },
      "source": [
        "# training modal\n",
        "triplet_model.fit_generator(generator=image_batch_generator(X, y, batch_size),\n",
        "                   steps_per_epoch=len(X)//batch_size,\n",
        "                   epochs=2000,\n",
        "                   verbose=1,\n",
        "                   initial_epoch= 1463,\n",
        "                   callbacks=callbacks_list)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1464/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1779\n",
            "Epoch 01464: loss improved from inf to 0.17714, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 212s 880ms/step - loss: 0.1771\n",
            "Epoch 1465/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1731\n",
            "Epoch 01465: loss improved from 0.17714 to 0.17392, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 199s 826ms/step - loss: 0.1739\n",
            "Epoch 1466/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1597\n",
            "Epoch 01466: loss improved from 0.17392 to 0.15899, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 198s 822ms/step - loss: 0.1590\n",
            "Epoch 1467/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1632\n",
            "Epoch 01467: loss did not improve from 0.15899\n",
            "241/241 [==============================] - 195s 810ms/step - loss: 0.1625\n",
            "Epoch 1468/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1718\n",
            "Epoch 01468: loss did not improve from 0.15899\n",
            "241/241 [==============================] - 195s 810ms/step - loss: 0.1711\n",
            "Epoch 1469/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1729\n",
            "Epoch 01469: loss did not improve from 0.15899\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1735\n",
            "Epoch 1470/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1572\n",
            "Epoch 01470: loss improved from 0.15899 to 0.15665, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 198s 821ms/step - loss: 0.1566\n",
            "Epoch 1471/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1687\n",
            "Epoch 01471: loss did not improve from 0.15665\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1686\n",
            "Epoch 1472/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1586\n",
            "Epoch 01472: loss did not improve from 0.15665\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1580\n",
            "Epoch 1473/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1742\n",
            "Epoch 01473: loss did not improve from 0.15665\n",
            "241/241 [==============================] - 195s 810ms/step - loss: 0.1744\n",
            "Epoch 1474/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1619\n",
            "Epoch 01474: loss did not improve from 0.15665\n",
            "241/241 [==============================] - 195s 807ms/step - loss: 0.1624\n",
            "Epoch 1475/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1489\n",
            "Epoch 01475: loss improved from 0.15665 to 0.14856, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 199s 824ms/step - loss: 0.1486\n",
            "Epoch 1476/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1572\n",
            "Epoch 01476: loss did not improve from 0.14856\n",
            "241/241 [==============================] - 195s 810ms/step - loss: 0.1566\n",
            "Epoch 1477/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1548\n",
            "Epoch 01477: loss did not improve from 0.14856\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1545\n",
            "Epoch 1478/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1401\n",
            "Epoch 01478: loss improved from 0.14856 to 0.13948, saving model to /content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5\n",
            "241/241 [==============================] - 198s 820ms/step - loss: 0.1395\n",
            "Epoch 1479/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1675\n",
            "Epoch 01479: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1668\n",
            "Epoch 1480/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1459\n",
            "Epoch 01480: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1453\n",
            "Epoch 1481/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1730\n",
            "Epoch 01481: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1723\n",
            "Epoch 1482/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1585\n",
            "Epoch 01482: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 807ms/step - loss: 0.1582\n",
            "Epoch 1483/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1630\n",
            "Epoch 01483: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1633\n",
            "Epoch 1484/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1652\n",
            "Epoch 01484: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 810ms/step - loss: 0.1657\n",
            "Epoch 1485/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1755\n",
            "Epoch 01485: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 809ms/step - loss: 0.1771\n",
            "Epoch 1486/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1796\n",
            "Epoch 01486: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 809ms/step - loss: 0.1793\n",
            "Epoch 1487/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1613\n",
            "Epoch 01487: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 809ms/step - loss: 0.1611\n",
            "Epoch 1488/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1765\n",
            "Epoch 01488: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 809ms/step - loss: 0.1765\n",
            "Epoch 1489/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1657\n",
            "Epoch 01489: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 807ms/step - loss: 0.1659\n",
            "Epoch 1490/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1447\n",
            "Epoch 01490: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 807ms/step - loss: 0.1442\n",
            "Epoch 1491/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1733\n",
            "Epoch 01491: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 809ms/step - loss: 0.1737\n",
            "Epoch 1492/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1776\n",
            "Epoch 01492: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1789\n",
            "Epoch 1493/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1795\n",
            "Epoch 01493: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1787\n",
            "Epoch 1494/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1705\n",
            "Epoch 01494: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 807ms/step - loss: 0.1699\n",
            "Epoch 1495/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1677\n",
            "Epoch 01495: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 806ms/step - loss: 0.1674\n",
            "Epoch 1496/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1606\n",
            "Epoch 01496: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 806ms/step - loss: 0.1599\n",
            "Epoch 1497/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1730\n",
            "Epoch 01497: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 807ms/step - loss: 0.1730\n",
            "Epoch 1498/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1626\n",
            "Epoch 01498: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 195s 808ms/step - loss: 0.1619\n",
            "Epoch 1499/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1616\n",
            "Epoch 01499: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 806ms/step - loss: 0.1609\n",
            "Epoch 1500/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1413\n",
            "Epoch 01500: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1408\n",
            "Epoch 1501/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1623\n",
            "Epoch 01501: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1625\n",
            "Epoch 1502/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1866\n",
            "Epoch 01502: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1858\n",
            "Epoch 1503/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1685\n",
            "Epoch 01503: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1697\n",
            "Epoch 1504/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1648\n",
            "Epoch 01504: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 804ms/step - loss: 0.1646\n",
            "Epoch 1505/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1684\n",
            "Epoch 01505: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1677\n",
            "Epoch 1506/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1723\n",
            "Epoch 01506: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 806ms/step - loss: 0.1720\n",
            "Epoch 1507/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1571\n",
            "Epoch 01507: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1564\n",
            "Epoch 1508/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1622\n",
            "Epoch 01508: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1621\n",
            "Epoch 1509/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1525\n",
            "Epoch 01509: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 194s 805ms/step - loss: 0.1533\n",
            "Epoch 1510/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1608\n",
            "Epoch 01510: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 797ms/step - loss: 0.1604\n",
            "Epoch 1511/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1464\n",
            "Epoch 01511: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1472\n",
            "Epoch 1512/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1415\n",
            "Epoch 01512: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1409\n",
            "Epoch 1513/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1421\n",
            "Epoch 01513: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 191s 794ms/step - loss: 0.1420\n",
            "Epoch 1514/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1655\n",
            "Epoch 01514: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1664\n",
            "Epoch 1515/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1632\n",
            "Epoch 01515: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1637\n",
            "Epoch 1516/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1623\n",
            "Epoch 01516: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1637\n",
            "Epoch 1517/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1610\n",
            "Epoch 01517: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1608\n",
            "Epoch 1518/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1789\n",
            "Epoch 01518: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1791\n",
            "Epoch 1519/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1814\n",
            "Epoch 01519: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1807\n",
            "Epoch 1520/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1684\n",
            "Epoch 01520: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 191s 794ms/step - loss: 0.1685\n",
            "Epoch 1521/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1494\n",
            "Epoch 01521: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1495\n",
            "Epoch 1522/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1532\n",
            "Epoch 01522: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1531\n",
            "Epoch 1523/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1519\n",
            "Epoch 01523: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1513\n",
            "Epoch 1524/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1858\n",
            "Epoch 01524: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1852\n",
            "Epoch 1525/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1507\n",
            "Epoch 01525: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1516\n",
            "Epoch 1526/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1669\n",
            "Epoch 01526: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 795ms/step - loss: 0.1662\n",
            "Epoch 1527/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1759\n",
            "Epoch 01527: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1768\n",
            "Epoch 1528/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1434\n",
            "Epoch 01528: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 191s 794ms/step - loss: 0.1434\n",
            "Epoch 1529/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1488\n",
            "Epoch 01529: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1495\n",
            "Epoch 1530/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1452\n",
            "Epoch 01530: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1446\n",
            "Epoch 1531/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1631\n",
            "Epoch 01531: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1630\n",
            "Epoch 1532/2000\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.1621\n",
            "Epoch 01532: loss did not improve from 0.13948\n",
            "241/241 [==============================] - 192s 796ms/step - loss: 0.1624\n",
            "Epoch 1533/2000\n",
            "196/241 [=======================>......] - ETA: 35s - loss: 0.1530"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWrncgxEFW1"
      },
      "source": [
        "#save 128 dim vector to array\n",
        "from tqdm import tqdm\n",
        "embs128 = []\n",
        "for x in tqdm(X):\n",
        "    image = x/255.\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    emb128 = triplet_model.predict([image, image, image])\n",
        "    embs128.append(emb128[0])\n",
        "    del image\n",
        "\n",
        "embs128 = np.array(embs128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRf7PTWmLfAQ"
      },
      "source": [
        "np.shape(embs128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-sRxhUqEw6T"
      },
      "source": [
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/embs128.pkl\", \"wb\") as f:\n",
        "    pickle.dump(embs128, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPJtAeinG4Tm"
      },
      "source": [
        "#Create LFW_128_labels.tsv\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/LFW_128_labels.tsv', 'w') as f:\n",
        "    for label in y:\n",
        "        l = str(name_map[label])\n",
        "        f.write(l + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtr9jyVpgva"
      },
      "source": [
        "#test modal\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/name_map1.pkl', 'rb') as f:\n",
        "    names = pickle.load(f)\n",
        "    names = np.array(names)\n",
        "    # names=names[2400:]\n",
        "np.shape(names)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quw06k8OIZ7b"
      },
      "source": [
        "#Load all vector embedding LFW of my model\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/embs128.pkl', 'rb') as f:\n",
        "    embs128 = pickle.load(f)\n",
        "    embs128 = np.array(embs128)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/LFW_128_labels.tsv', 'r') as f:\n",
        "    names_embs128 = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmyLh-S8yj2_"
      },
      "source": [
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsUO58fENK8L"
      },
      "source": [
        "cnn_face_detector = dlib.cnn_face_detection_model_v1('/content/drive/MyDrive/Colab Notebooks/mmod_human_face_detector.dat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWhjg9ftpQAb"
      },
      "source": [
        "\n",
        "# image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/lfw/Yoko_Ono/Yoko_Ono_0002.jpg')\n",
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/sample.jpg')\n",
        "\n",
        "start = time.time()\n",
        "# Khai báo việc sử dụng các hàm của dlib\n",
        "hog_face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "faces_hog = hog_face_detector(image, 1)\n",
        "\n",
        "for face in faces_hog:\n",
        "    x = face.left()\n",
        "    y = face.top()\n",
        "    w = face.right() - x\n",
        "    h = face.bottom() - y\n",
        "    frame = image[y:y+h, x:x+w]\n",
        "    frame = cv2.resize(frame, (221, 221))\n",
        "    frame = frame /255.\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    emb128 = triplet_model.predict([frame, frame, frame])\n",
        "    \n",
        "    minimum = 99999\n",
        "    person = -1\n",
        "    for k, e in enumerate(embs128):\n",
        "        #Euler distance\n",
        "        dist = np.linalg.norm(emb128-e)\n",
        "        if dist < minimum:\n",
        "            minimum = dist\n",
        "            person = k\n",
        "    end = time.time()\n",
        "    \n",
        "    cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "    cv2.putText(image, str(names_embs128[person])[0:-1], (x - 10, y - 10),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "print(\"HOG + SVM Execution time: \" + str(end-start))\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xnJTfUxUH48"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "print(\"Loading pre-trained weight for CNN\")\n",
        "triplet_model.load_weights('/content/drive/MyDrive/Colab Notebooks/triplet_weight0.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BOYb3cuyns6"
      },
      "source": [
        "\n",
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/sample.jpg')\n",
        "\n",
        "\n",
        "# Thực hiện xác định bằng CNN\n",
        "start = time.time()\n",
        "faces_cnn = cnn_face_detector(image, 1)\n",
        "\n",
        "\n",
        "for face in faces_cnn:\n",
        "    x = face.rect.left()\n",
        "    y = face.rect.top()\n",
        "    w = face.rect.right() - x\n",
        "    h = face.rect.bottom() - y\n",
        "    frame = image[y:y+h, x:x+w]\n",
        "    frame = cv2.resize(frame, (221, 221))\n",
        "    frame = frame /255.\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    emb128 = triplet_model.predict([frame, frame, frame])\n",
        "    minimum = 99999\n",
        "    person = -1\n",
        "    for k, e in enumerate(embs128):\n",
        "        #Euler distance\n",
        "        dist = np.linalg.norm(emb128-e)\n",
        "        if dist < minimum:\n",
        "            minimum = dist\n",
        "            person = k\n",
        "            # print(dist)\n",
        "    end = time.time()\n",
        "\n",
        "    cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,255), 2)\n",
        "    cv2.putText(image, str(names_embs128[person])[0:-1], (x - 10, y - 10),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "print(\"CNN Execution time: \" + str(end-start))\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}