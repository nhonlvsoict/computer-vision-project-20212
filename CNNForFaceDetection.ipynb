{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNForFaceDetection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPp+F7PBkjiAsTBiJ0FZhvL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS0Sh5WmIB0M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir='/content/drive/MyDrive/Colab Notebooks/train/'\n",
        "test_dir='/content/drive/MyDrive/Colab Notebooks/test/'"
      ],
      "metadata": {
        "id": "JRBic6KjIJDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_count=100\n",
        "reg_val=[]\n",
        "lr_val=[]\n",
        "test_loss=[]\n",
        "test_acc=[]\n",
        "\n",
        "for i in range(max_count):\n",
        "\n",
        "\tprint (\"*\"*30)\n",
        "\tprint (str(i+1)+\"/\"+str(max_count))\n",
        "\tprint (\"*\"*30)\n",
        "# Sampling learning rate and regularization from a uniform distribution\n",
        "\n",
        "        reg=10**(np.random.uniform(-4,0))\n",
        "        lr=10**(np.random.uniform(-3,-4))"
      ],
      "metadata": {
        "id": "AdXaxM6vITDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the model\n",
        "\n",
        "model=models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(60,60,3)))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512,activation='relu',kernel_regularizer=regularizers.l2(reg)))\n",
        "\n",
        "model.add(layers.Dense(1,activation='sigmoid',kernel_regularizer=regularizers.l2(reg)))\n"
      ],
      "metadata": {
        "id": "jzQNOakwITuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "gVeuRLIsIZyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=lr),\n",
        "             metrics=['acc'])"
      ],
      "metadata": {
        "id": "coPrMkdPIaJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rescale all the images by 1/255\n",
        "train_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "                train_dir,\n",
        "                target_size=(60,60),\n",
        "                batch_size=20,\n",
        "                class_mode='binary')\n",
        "test_generator=test_datagen.flow_from_directory(\n",
        "                test_dir,\n",
        "                target_size=(60,60),\n",
        "                batch_size=20,\n",
        "                class_mode='binary'\n",
        "                )\n",
        "#Fit the model using batch generator\n",
        "history=model.fit_generator(\n",
        "        \ttrain_generator,\n",
        "        \tsteps_per_epoch=100,\n",
        "        \tepochs=5,\n",
        "        \tvalidation_data=test_generator,\n",
        "        \tvalidation_steps=50)\n",
        "\n",
        "reg_val.append(reg)\n",
        "lr_val.append(lr)\n",
        "test_loss.append(history.history['val_loss'])\n",
        "test_acc.append(history.history['val_acc'])"
      ],
      "metadata": {
        "id": "6O6CRWuzIgv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index1=0\n",
        "index2=0\n",
        "max_test_acc=max(test_acc[0])\n",
        "min_test_loss=min(test_loss[0])\n",
        "for i in range(max_count):\n",
        "\ttemp1=max(test_acc[i])\n",
        "\tif(temp1>=max_test_acc):\n",
        "    \t\tmax_test_acc=temp1\n",
        "\t\tindex1=i\n",
        "        temp2=min(test_loss[i])\n",
        "\tif(temp2<min_test_loss):\n",
        "\t\tmin_test_loss=temp2\n",
        "\t\tindex2=i\t"
      ],
      "metadata": {
        "id": "TT5L3oSYIwhT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}